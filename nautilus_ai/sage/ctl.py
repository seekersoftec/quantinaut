import json
import click
import numpy as np
import pandas as pd
from tqdm import tqdm
from datetime import datetime, timedelta
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor
from nautilus_ai.common import handle_config

np.random.seed(100)


@click.group()
def sage_ctl():
    """
    ğŸ“Š Sage CLI â€” Intelligent Trading Automation

    A unified control interface for managing data, ML models/pipelines, and automated trading operations.

    ğŸ› ï¸  Core Commands: \n
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n
    âš™ï¸  sage config     â†’ Load and inspect configuration files \n
    ğŸ”—  sage merge      â†’ Merge multiple data sources \n
    ğŸ§   sage generate   â†’ Generate features, labels and signals \n
    ğŸ‹ï¸  sage train      â†’ Train ML models \n
    ğŸ¤–  sage predict    â†’ Run predictions (including rolling forecasts) \n
    ğŸ§ª  sage simulate   â†’ Simulate/backtest strategies \n
    ğŸ’¸  sage live       â†’ Execute trades in live/paper mode \n
    """
    pass


@sage_ctl.command(name="config", help="âš™ï¸  Load and display the contents of a configuration file")
@click.option(
    '--file', '-f',
    type=click.Path(exists=True, dir_okay=False, readable=True),
    required=True,
    help='Path to the configuration file (YAML/TOML/JSON)'
)
def read_config(file):
    """
    Load and display the contents of a configuration file.
    
    Supports: JSON, YAML, TOML, INI, and NumPy files.

    Example:
        sage config -f configs/example.json
    """
    try:
        config = handle_config(file)
    except Exception as e:
        click.secho(f"âŒ Failed to load config: {e}", fg='red')
        raise SystemExit(1)

    click.secho(f"\nâœ… Loaded configuration from: {file}\n", fg='green')
    click.echo(json.dumps(config, indent=4, default=str))


# Data Preparation (Merge)


"""
Create one output file from multiple input data files. 
"""
@sage_ctl.command(name="merge")
@click.option(
    '--file', '-f',
    type=click.Path(exists=True, readable=True, dir_okay=False),
    required=True,
    help="Path to the configuration file"
)
def merge(file):
    """
    ğŸ§© Merge multiple data sources into a unified dataframe.

    Reads CSV data sources defined in the config, aligns them on a regular time index, 
    interpolates if specified, and stores a merged output file.
    """
    from nautilus_ai.sage.helpers import merge_data_sources

    config = handle_config(file)
    time_column = config["time_column"]
    data_sources = config.get("data_sources", [])

    if not data_sources:
        click.secho("âŒ ERROR: No data sources defined.", fg="red")
        return

    now = datetime.now()
    data_path = Path(config["data_folder"])
    symbol = config["symbol"]

    is_train = config.get("train")
    if is_train:
        window_size = config.get("train_length")
    else:
        window_size = config.get("predict_length")
    features_horizon = config.get("features_horizon")
    if window_size:
        window_size += features_horizon

    for ds in data_sources:
        folder = ds.get("folder")
        file_name = ds.get("file", folder)
        file_path = Path(data_path / folder / file_name)
        if not file_path.suffix:
            file_path = file_path.with_suffix(".csv")

        if not file_path.exists():
            click.secho(f"âŒ File not found: {file_path}", fg="red")
            return

        if file_path.suffix == ".parquet":
            df = pd.read_parquet(file_path)
        elif file_path.suffix == ".csv":
            df = pd.read_csv(file_path, parse_dates=[time_column], date_format="ISO8601")
        else:
            click.secho(f"âŒ Unsupported input format: {file_path.suffix}", fg="red")
            return
        click.secho(f"ğŸ“„ Loaded {file_path} with {len(df)} rows", fg="green")
        if window_size:
            df = df.tail(window_size)
            df = df.reset_index(drop=True)
        ds["df"] = df

    df_merged = merge_data_sources(data_sources, config)

    out_path = data_path / symbol / config.get("merge_file_name")
    out_path.parent.mkdir(parents=True, exist_ok=True)

    df_merged = df_merged.reset_index()
    if out_path.suffix == ".parquet":
        df_merged.to_parquet(out_path, index=False)
    elif out_path.suffix == ".csv":
        df_merged.to_csv(out_path, index=False)
    else:
        click.secho(f"âŒ Unsupported output format: {out_path.suffix}", fg="red")
        return

    click.secho(f"âœ… Merged file saved: {out_path} with {len(df_merged)} rows", fg="cyan")
    click.secho(f"â±ï¸ Completed in {str(datetime.now() - now).split('.')[0]}", fg="blue")


# Features

# Labels

# Train Model

# Test Model

# Save Model
